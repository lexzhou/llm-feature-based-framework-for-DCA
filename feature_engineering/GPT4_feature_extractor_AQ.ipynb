{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ag8gtk78FtpN",
    "outputId": "83bc2f92-06b2-40fa-837d-07895943c10d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: convokit in c:\\users\\17245\\anaconda3\\lib\\site-packages (3.0.0)\n",
      "Requirement already satisfied: matplotlib>=3.0.0 in c:\\users\\17245\\anaconda3\\lib\\site-packages (from convokit) (3.8.0)\n",
      "Requirement already satisfied: pandas>=0.23.4 in c:\\users\\17245\\anaconda3\\lib\\site-packages (from convokit) (2.1.4)\n",
      "Requirement already satisfied: msgpack-numpy>=0.4.3.2 in c:\\users\\17245\\anaconda3\\lib\\site-packages (from convokit) (0.4.8)\n",
      "Requirement already satisfied: spacy>=2.3.5 in c:\\users\\17245\\anaconda3\\lib\\site-packages (from convokit) (3.7.4)\n",
      "Requirement already satisfied: scipy>=1.1.0 in c:\\users\\17245\\anaconda3\\lib\\site-packages (from convokit) (1.11.4)\n",
      "Requirement already satisfied: scikit-learn>=0.20.0 in c:\\users\\17245\\anaconda3\\lib\\site-packages (from convokit) (1.2.2)\n",
      "Requirement already satisfied: nltk>=3.4 in c:\\users\\17245\\anaconda3\\lib\\site-packages (from convokit) (3.8.1)\n",
      "Requirement already satisfied: dill>=0.2.9 in c:\\users\\17245\\anaconda3\\lib\\site-packages (from convokit) (0.3.7)\n",
      "Requirement already satisfied: joblib>=0.13.2 in c:\\users\\17245\\anaconda3\\lib\\site-packages (from convokit) (1.2.0)\n",
      "Requirement already satisfied: clean-text>=0.6.0 in c:\\users\\17245\\anaconda3\\lib\\site-packages (from convokit) (0.6.0)\n",
      "Requirement already satisfied: unidecode>=1.1.1 in c:\\users\\17245\\anaconda3\\lib\\site-packages (from convokit) (1.2.0)\n",
      "Requirement already satisfied: tqdm>=4.64.0 in c:\\users\\17245\\anaconda3\\lib\\site-packages (from convokit) (4.66.2)\n",
      "Requirement already satisfied: pymongo>=4.0 in c:\\users\\17245\\anaconda3\\lib\\site-packages (from convokit) (4.6.3)\n",
      "Requirement already satisfied: pyyaml>=5.4.1 in c:\\users\\17245\\anaconda3\\lib\\site-packages (from convokit) (6.0.1)\n",
      "Requirement already satisfied: dnspython>=1.16.0 in c:\\users\\17245\\anaconda3\\lib\\site-packages (from convokit) (2.6.1)\n",
      "Requirement already satisfied: emoji<2.0.0,>=1.0.0 in c:\\users\\17245\\anaconda3\\lib\\site-packages (from clean-text>=0.6.0->convokit) (1.7.0)\n",
      "Requirement already satisfied: ftfy<7.0,>=6.0 in c:\\users\\17245\\anaconda3\\lib\\site-packages (from clean-text>=0.6.0->convokit) (6.2.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\17245\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->convokit) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\17245\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->convokit) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\17245\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->convokit) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\17245\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->convokit) (1.4.4)\n",
      "Requirement already satisfied: numpy<2,>=1.21 in c:\\users\\17245\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->convokit) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\17245\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->convokit) (23.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\17245\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->convokit) (10.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\17245\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->convokit) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\17245\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->convokit) (2.8.2)\n",
      "Requirement already satisfied: msgpack>=0.5.2 in c:\\users\\17245\\anaconda3\\lib\\site-packages (from msgpack-numpy>=0.4.3.2->convokit) (1.0.3)\n",
      "Requirement already satisfied: click in c:\\users\\17245\\anaconda3\\lib\\site-packages (from nltk>=3.4->convokit) (8.1.7)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\17245\\anaconda3\\lib\\site-packages (from nltk>=3.4->convokit) (2023.10.3)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\17245\\anaconda3\\lib\\site-packages (from pandas>=0.23.4->convokit) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\17245\\anaconda3\\lib\\site-packages (from pandas>=0.23.4->convokit) (2023.3)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\17245\\anaconda3\\lib\\site-packages (from scikit-learn>=0.20.0->convokit) (2.2.0)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\17245\\anaconda3\\lib\\site-packages (from spacy>=2.3.5->convokit) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\17245\\anaconda3\\lib\\site-packages (from spacy>=2.3.5->convokit) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\17245\\anaconda3\\lib\\site-packages (from spacy>=2.3.5->convokit) (1.0.10)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\17245\\anaconda3\\lib\\site-packages (from spacy>=2.3.5->convokit) (2.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\17245\\anaconda3\\lib\\site-packages (from spacy>=2.3.5->convokit) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in c:\\users\\17245\\anaconda3\\lib\\site-packages (from spacy>=2.3.5->convokit) (8.2.3)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\17245\\anaconda3\\lib\\site-packages (from spacy>=2.3.5->convokit) (1.1.2)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\17245\\anaconda3\\lib\\site-packages (from spacy>=2.3.5->convokit) (2.4.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\17245\\anaconda3\\lib\\site-packages (from spacy>=2.3.5->convokit) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in c:\\users\\17245\\anaconda3\\lib\\site-packages (from spacy>=2.3.5->convokit) (0.3.4)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in c:\\users\\17245\\anaconda3\\lib\\site-packages (from spacy>=2.3.5->convokit) (0.9.4)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in c:\\users\\17245\\anaconda3\\lib\\site-packages (from spacy>=2.3.5->convokit) (5.2.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\17245\\anaconda3\\lib\\site-packages (from spacy>=2.3.5->convokit) (2.31.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in c:\\users\\17245\\anaconda3\\lib\\site-packages (from spacy>=2.3.5->convokit) (2.7.0)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\17245\\anaconda3\\lib\\site-packages (from spacy>=2.3.5->convokit) (3.1.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\17245\\anaconda3\\lib\\site-packages (from spacy>=2.3.5->convokit) (68.2.2)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\17245\\anaconda3\\lib\\site-packages (from spacy>=2.3.5->convokit) (3.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\17245\\anaconda3\\lib\\site-packages (from tqdm>=4.64.0->convokit) (0.4.6)\n",
      "Requirement already satisfied: wcwidth<0.3.0,>=0.2.12 in c:\\users\\17245\\anaconda3\\lib\\site-packages (from ftfy<7.0,>=6.0->clean-text>=0.6.0->convokit) (0.2.13)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\17245\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy>=2.3.5->convokit) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.1 in c:\\users\\17245\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy>=2.3.5->convokit) (2.18.1)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in c:\\users\\17245\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy>=2.3.5->convokit) (4.9.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\17245\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib>=3.0.0->convokit) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\17245\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.3.5->convokit) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\17245\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.3.5->convokit) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\17245\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.3.5->convokit) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\17245\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.3.5->convokit) (2024.2.2)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in c:\\users\\17245\\anaconda3\\lib\\site-packages (from thinc<8.3.0,>=8.2.2->spacy>=2.3.5->convokit) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\17245\\anaconda3\\lib\\site-packages (from thinc<8.3.0,>=8.2.2->spacy>=2.3.5->convokit) (0.1.4)\n",
      "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in c:\\users\\17245\\anaconda3\\lib\\site-packages (from weasel<0.4.0,>=0.1.0->spacy>=2.3.5->convokit) (0.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\17245\\anaconda3\\lib\\site-packages (from jinja2->spacy>=2.3.5->convokit) (2.1.3)\n",
      "Requirement already satisfied: transformers[torch] in c:\\users\\17245\\anaconda3\\lib\\site-packages (4.40.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\17245\\anaconda3\\lib\\site-packages (from transformers[torch]) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in c:\\users\\17245\\anaconda3\\lib\\site-packages (from transformers[torch]) (0.22.2)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\17245\\anaconda3\\lib\\site-packages (from transformers[torch]) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\17245\\anaconda3\\lib\\site-packages (from transformers[torch]) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\17245\\anaconda3\\lib\\site-packages (from transformers[torch]) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\17245\\anaconda3\\lib\\site-packages (from transformers[torch]) (2023.10.3)\n",
      "Requirement already satisfied: requests in c:\\users\\17245\\anaconda3\\lib\\site-packages (from transformers[torch]) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in c:\\users\\17245\\anaconda3\\lib\\site-packages (from transformers[torch]) (0.19.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\17245\\anaconda3\\lib\\site-packages (from transformers[torch]) (0.4.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\17245\\anaconda3\\lib\\site-packages (from transformers[torch]) (4.66.2)\n",
      "Requirement already satisfied: torch in c:\\users\\17245\\anaconda3\\lib\\site-packages (from transformers[torch]) (2.2.2)\n",
      "Requirement already satisfied: accelerate>=0.21.0 in c:\\users\\17245\\anaconda3\\lib\\site-packages (from transformers[torch]) (0.29.3)\n",
      "Requirement already satisfied: psutil in c:\\users\\17245\\anaconda3\\lib\\site-packages (from accelerate>=0.21.0->transformers[torch]) (5.9.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\17245\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.19.3->transformers[torch]) (2023.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\17245\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.19.3->transformers[torch]) (4.9.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\17245\\anaconda3\\lib\\site-packages (from torch->transformers[torch]) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\17245\\anaconda3\\lib\\site-packages (from torch->transformers[torch]) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\17245\\anaconda3\\lib\\site-packages (from torch->transformers[torch]) (3.1.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\17245\\anaconda3\\lib\\site-packages (from tqdm>=4.27->transformers[torch]) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\17245\\anaconda3\\lib\\site-packages (from requests->transformers[torch]) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\17245\\anaconda3\\lib\\site-packages (from requests->transformers[torch]) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\17245\\anaconda3\\lib\\site-packages (from requests->transformers[torch]) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\17245\\anaconda3\\lib\\site-packages (from requests->transformers[torch]) (2024.2.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\17245\\anaconda3\\lib\\site-packages (from jinja2->torch->transformers[torch]) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\17245\\anaconda3\\lib\\site-packages (from sympy->torch->transformers[torch]) (1.3.0)\n",
      "Requirement already satisfied: accelerate in c:\\users\\17245\\anaconda3\\lib\\site-packages (0.29.3)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\17245\\anaconda3\\lib\\site-packages (from accelerate) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\17245\\anaconda3\\lib\\site-packages (from accelerate) (23.1)\n",
      "Requirement already satisfied: psutil in c:\\users\\17245\\anaconda3\\lib\\site-packages (from accelerate) (5.9.0)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\17245\\anaconda3\\lib\\site-packages (from accelerate) (6.0.1)\n",
      "Requirement already satisfied: torch>=1.10.0 in c:\\users\\17245\\anaconda3\\lib\\site-packages (from accelerate) (2.2.2)\n",
      "Requirement already satisfied: huggingface-hub in c:\\users\\17245\\anaconda3\\lib\\site-packages (from accelerate) (0.22.2)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in c:\\users\\17245\\anaconda3\\lib\\site-packages (from accelerate) (0.4.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\17245\\anaconda3\\lib\\site-packages (from torch>=1.10.0->accelerate) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\17245\\anaconda3\\lib\\site-packages (from torch>=1.10.0->accelerate) (4.9.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\17245\\anaconda3\\lib\\site-packages (from torch>=1.10.0->accelerate) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\17245\\anaconda3\\lib\\site-packages (from torch>=1.10.0->accelerate) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\17245\\anaconda3\\lib\\site-packages (from torch>=1.10.0->accelerate) (3.1.3)\n",
      "Requirement already satisfied: fsspec in c:\\users\\17245\\anaconda3\\lib\\site-packages (from torch>=1.10.0->accelerate) (2023.10.0)\n",
      "Requirement already satisfied: requests in c:\\users\\17245\\anaconda3\\lib\\site-packages (from huggingface-hub->accelerate) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\17245\\anaconda3\\lib\\site-packages (from huggingface-hub->accelerate) (4.66.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\17245\\anaconda3\\lib\\site-packages (from tqdm>=4.42.1->huggingface-hub->accelerate) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\17245\\anaconda3\\lib\\site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\17245\\anaconda3\\lib\\site-packages (from requests->huggingface-hub->accelerate) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\17245\\anaconda3\\lib\\site-packages (from requests->huggingface-hub->accelerate) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\17245\\anaconda3\\lib\\site-packages (from requests->huggingface-hub->accelerate) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\17245\\anaconda3\\lib\\site-packages (from requests->huggingface-hub->accelerate) (2024.2.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\17245\\anaconda3\\lib\\site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
      "Collecting git+https://github.com/allenai/longformer.git\n",
      "  Cloning https://github.com/allenai/longformer.git to c:\\users\\17245\\appdata\\local\\temp\\pip-req-build-72gi44uy\n",
      "  Resolved https://github.com/allenai/longformer.git to commit caefee668e39cacdece7dd603a0bebf24df6d8ca\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting transformers@ git+http://github.com/ibeltagy/transformers.git@longformer_encoder_decoder#egg=transformers (from longformer==0.1)\n",
      "  Cloning http://github.com/ibeltagy/transformers.git (to revision longformer_encoder_decoder) to c:\\users\\17245\\appdata\\local\\temp\\pip-install-g6jeb9si\\transformers_9890f9da687c4a98ab06ffe32bb4da31\n",
      "  Resolved http://github.com/ibeltagy/transformers.git to commit 52d6236dc15ad5142b4146ff74d2ec973fa3da22\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting pytorch-lightning@ git+http://github.com/ibeltagy/pytorch-lightning.git@v0.8.5_fixes#egg=pytorch-lightning (from longformer==0.1)\n",
      "  Cloning http://github.com/ibeltagy/pytorch-lightning.git (to revision v0.8.5_fixes) to c:\\users\\17245\\appdata\\local\\temp\\pip-install-g6jeb9si\\pytorch-lightning_3bb7c3f9e9164654a3cc2f2b04dff914\n",
      "  Resolved http://github.com/ibeltagy/pytorch-lightning.git to commit 7ed5d849a0c76fa2199162f0283507e36601ded6\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Requirement already satisfied: torch>=1.6.0 in c:\\users\\17245\\anaconda3\\lib\\site-packages (from longformer==0.1) (2.2.2)\n",
      "Collecting tensorboardX (from longformer==0.1)\n",
      "  Using cached tensorboardX-2.6.2.2-py2.py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting test-tube==0.7.5 (from longformer==0.1)\n",
      "  Using cached test_tube-0.7.5-py3-none-any.whl\n",
      "Collecting nlp (from longformer==0.1)\n",
      "  Using cached nlp-0.4.0-py3-none-any.whl.metadata (5.0 kB)\n",
      "Collecting rouge_score (from longformer==0.1)\n",
      "  Using cached rouge_score-0.1.2-py3-none-any.whl\n",
      "Requirement already satisfied: pandas>=0.20.3 in c:\\users\\17245\\anaconda3\\lib\\site-packages (from test-tube==0.7.5->longformer==0.1) (2.1.4)\n",
      "Requirement already satisfied: numpy>=1.13.3 in c:\\users\\17245\\anaconda3\\lib\\site-packages (from test-tube==0.7.5->longformer==0.1) (1.26.4)\n",
      "Requirement already satisfied: imageio>=2.3.0 in c:\\users\\17245\\anaconda3\\lib\\site-packages (from test-tube==0.7.5->longformer==0.1) (2.33.1)\n",
      "Collecting tensorboard>=1.15.0 (from test-tube==0.7.5->longformer==0.1)\n",
      "  Using cached tensorboard-2.16.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: future in c:\\users\\17245\\anaconda3\\lib\\site-packages (from test-tube==0.7.5->longformer==0.1) (0.18.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\17245\\anaconda3\\lib\\site-packages (from torch>=1.6.0->longformer==0.1) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\17245\\anaconda3\\lib\\site-packages (from torch>=1.6.0->longformer==0.1) (4.9.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\17245\\anaconda3\\lib\\site-packages (from torch>=1.6.0->longformer==0.1) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\17245\\anaconda3\\lib\\site-packages (from torch>=1.6.0->longformer==0.1) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\17245\\anaconda3\\lib\\site-packages (from torch>=1.6.0->longformer==0.1) (3.1.3)\n",
      "Requirement already satisfied: fsspec in c:\\users\\17245\\anaconda3\\lib\\site-packages (from torch>=1.6.0->longformer==0.1) (2023.10.0)\n",
      "Requirement already satisfied: pyarrow>=0.16.0 in c:\\users\\17245\\anaconda3\\lib\\site-packages (from nlp->longformer==0.1) (14.0.2)\n",
      "Requirement already satisfied: dill in c:\\users\\17245\\anaconda3\\lib\\site-packages (from nlp->longformer==0.1) (0.3.7)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\17245\\anaconda3\\lib\\site-packages (from nlp->longformer==0.1) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\17245\\anaconda3\\lib\\site-packages (from nlp->longformer==0.1) (4.66.2)\n",
      "Collecting xxhash (from nlp->longformer==0.1)\n",
      "  Using cached xxhash-3.4.1-cp311-cp311-win_amd64.whl.metadata (12 kB)\n",
      "Requirement already satisfied: PyYAML>=5.1 in c:\\users\\17245\\anaconda3\\lib\\site-packages (from pytorch-lightning@ git+http://github.com/ibeltagy/pytorch-lightning.git@v0.8.5_fixes#egg=pytorch-lightning->longformer==0.1) (6.0.1)\n",
      "Collecting absl-py (from rouge_score->longformer==0.1)\n",
      "  Using cached absl_py-2.1.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: nltk in c:\\users\\17245\\anaconda3\\lib\\site-packages (from rouge_score->longformer==0.1) (3.8.1)\n",
      "Requirement already satisfied: six>=1.14.0 in c:\\users\\17245\\anaconda3\\lib\\site-packages (from rouge_score->longformer==0.1) (1.16.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\17245\\anaconda3\\lib\\site-packages (from tensorboardX->longformer==0.1) (23.1)\n",
      "Requirement already satisfied: protobuf>=3.20 in c:\\users\\17245\\anaconda3\\lib\\site-packages (from tensorboardX->longformer==0.1) (3.20.3)\n",
      "Collecting tokenizers==0.8.1.rc2 (from transformers@ git+http://github.com/ibeltagy/transformers.git@longformer_encoder_decoder#egg=transformers->longformer==0.1)\n",
      "  Using cached tokenizers-0.8.1rc2.tar.gz (97 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\17245\\anaconda3\\lib\\site-packages (from transformers@ git+http://github.com/ibeltagy/transformers.git@longformer_encoder_decoder#egg=transformers->longformer==0.1) (2023.10.3)\n",
      "Collecting sentencepiece!=0.1.92 (from transformers@ git+http://github.com/ibeltagy/transformers.git@longformer_encoder_decoder#egg=transformers->longformer==0.1)\n",
      "  Using cached sentencepiece-0.2.0-cp311-cp311-win_amd64.whl.metadata (8.3 kB)\n",
      "Collecting sacremoses (from transformers@ git+http://github.com/ibeltagy/transformers.git@longformer_encoder_decoder#egg=transformers->longformer==0.1)\n",
      "  Using cached sacremoses-0.1.1-py3-none-any.whl.metadata (8.3 kB)\n",
      "Requirement already satisfied: pillow>=8.3.2 in c:\\users\\17245\\anaconda3\\lib\\site-packages (from imageio>=2.3.0->test-tube==0.7.5->longformer==0.1) (10.3.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\17245\\anaconda3\\lib\\site-packages (from pandas>=0.20.3->test-tube==0.7.5->longformer==0.1) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\17245\\anaconda3\\lib\\site-packages (from pandas>=0.20.3->test-tube==0.7.5->longformer==0.1) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\17245\\anaconda3\\lib\\site-packages (from pandas>=0.20.3->test-tube==0.7.5->longformer==0.1) (2023.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\17245\\anaconda3\\lib\\site-packages (from requests>=2.19.0->nlp->longformer==0.1) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\17245\\anaconda3\\lib\\site-packages (from requests>=2.19.0->nlp->longformer==0.1) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\17245\\anaconda3\\lib\\site-packages (from requests>=2.19.0->nlp->longformer==0.1) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\17245\\anaconda3\\lib\\site-packages (from requests>=2.19.0->nlp->longformer==0.1) (2024.2.2)\n",
      "Collecting grpcio>=1.48.2 (from tensorboard>=1.15.0->test-tube==0.7.5->longformer==0.1)\n",
      "  Using cached grpcio-1.62.2-cp311-cp311-win_amd64.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\17245\\anaconda3\\lib\\site-packages (from tensorboard>=1.15.0->test-tube==0.7.5->longformer==0.1) (3.4.1)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\users\\17245\\anaconda3\\lib\\site-packages (from tensorboard>=1.15.0->test-tube==0.7.5->longformer==0.1) (68.2.2)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard>=1.15.0->test-tube==0.7.5->longformer==0.1)\n",
      "  Using cached tensorboard_data_server-0.7.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\17245\\anaconda3\\lib\\site-packages (from tensorboard>=1.15.0->test-tube==0.7.5->longformer==0.1) (2.2.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\17245\\anaconda3\\lib\\site-packages (from tqdm>=4.27->nlp->longformer==0.1) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\17245\\anaconda3\\lib\\site-packages (from jinja2->torch>=1.6.0->longformer==0.1) (2.1.3)\n",
      "Requirement already satisfied: click in c:\\users\\17245\\anaconda3\\lib\\site-packages (from nltk->rouge_score->longformer==0.1) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\17245\\anaconda3\\lib\\site-packages (from nltk->rouge_score->longformer==0.1) (1.2.0)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\17245\\anaconda3\\lib\\site-packages (from sympy->torch>=1.6.0->longformer==0.1) (1.3.0)\n",
      "Using cached nlp-0.4.0-py3-none-any.whl (1.7 MB)\n",
      "Using cached tensorboardX-2.6.2.2-py2.py3-none-any.whl (101 kB)\n",
      "Using cached sentencepiece-0.2.0-cp311-cp311-win_amd64.whl (991 kB)\n",
      "Using cached tensorboard-2.16.2-py3-none-any.whl (5.5 MB)\n",
      "Using cached absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
      "Using cached sacremoses-0.1.1-py3-none-any.whl (897 kB)\n",
      "Using cached xxhash-3.4.1-cp311-cp311-win_amd64.whl (29 kB)\n",
      "Using cached grpcio-1.62.2-cp311-cp311-win_amd64.whl (3.8 MB)\n",
      "Using cached tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)\n",
      "Building wheels for collected packages: longformer, pytorch-lightning, transformers, tokenizers\n",
      "  Building wheel for longformer (setup.py): started\n",
      "  Building wheel for longformer (setup.py): finished with status 'done'\n",
      "  Created wheel for longformer: filename=longformer-0.1-py3-none-any.whl size=549254 sha256=a05b7102d68222746d584a50b5623493ad74a425244314d97fc97424af810a6b\n",
      "  Stored in directory: C:\\Users\\17245\\AppData\\Local\\Temp\\pip-ephem-wheel-cache-dc71mb3h\\wheels\\75\\1d\\fd\\61f80e7af78351695151ed66052bc9f5a1d496f4d52ce66c86\n",
      "  Building wheel for pytorch-lightning (pyproject.toml): started\n",
      "  Building wheel for pytorch-lightning (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for pytorch-lightning: filename=pytorch_lightning-0.8.5-py3-none-any.whl size=315699 sha256=bf204d8a9d4e3d4577d3be17b1c20eaf07d486b524c174ea0007e4ec8cceb990\n",
      "  Stored in directory: C:\\Users\\17245\\AppData\\Local\\Temp\\pip-ephem-wheel-cache-dc71mb3h\\wheels\\ae\\6e\\07\\f116f6cb333508789f2e6a06d2fe6c8143e1e1b3aea80ac08c\n",
      "  Building wheel for transformers (setup.py): started\n",
      "  Building wheel for transformers (setup.py): finished with status 'done'\n",
      "  Created wheel for transformers: filename=transformers-3.1.0-py3-none-any.whl size=889347 sha256=715fa67d9115704ea402cb87d6353ca74ba89f28c64077db5a2a62aed89e1717\n",
      "  Stored in directory: C:\\Users\\17245\\AppData\\Local\\Temp\\pip-ephem-wheel-cache-dc71mb3h\\wheels\\f2\\5b\\3f\\929e90fb067ba92e8bed96b97c266c470aaa7299e9349f0614\n",
      "  Building wheel for tokenizers (pyproject.toml): started\n",
      "  Building wheel for tokenizers (pyproject.toml): finished with status 'error'\n",
      "Successfully built longformer pytorch-lightning transformers\n",
      "Failed to build tokenizers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Running command git clone --filter=blob:none --quiet https://github.com/allenai/longformer.git 'C:\\Users\\17245\\AppData\\Local\\Temp\\pip-req-build-72gi44uy'\n",
      "  Running command git clone --filter=blob:none --quiet http://github.com/ibeltagy/transformers.git 'C:\\Users\\17245\\AppData\\Local\\Temp\\pip-install-g6jeb9si\\transformers_9890f9da687c4a98ab06ffe32bb4da31'\n",
      "  warning: redirecting to https://github.com/ibeltagy/transformers.git/\n",
      "  Running command git checkout -b longformer_encoder_decoder --track origin/longformer_encoder_decoder\n",
      "  warning: redirecting to https://github.com/ibeltagy/transformers.git/\n",
      "  branch 'longformer_encoder_decoder' set up to track 'origin/longformer_encoder_decoder'.\n",
      "  Switched to a new branch 'longformer_encoder_decoder'\n",
      "  Running command git clone --filter=blob:none --quiet http://github.com/ibeltagy/pytorch-lightning.git 'C:\\Users\\17245\\AppData\\Local\\Temp\\pip-install-g6jeb9si\\pytorch-lightning_3bb7c3f9e9164654a3cc2f2b04dff914'\n",
      "  warning: redirecting to https://github.com/ibeltagy/pytorch-lightning.git/\n",
      "  Running command git checkout -b v0.8.5_fixes --track origin/v0.8.5_fixes\n",
      "  warning: redirecting to https://github.com/ibeltagy/pytorch-lightning.git/\n",
      "  branch 'v0.8.5_fixes' set up to track 'origin/v0.8.5_fixes'.\n",
      "  Switched to a new branch 'v0.8.5_fixes'\n",
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  Building wheel for tokenizers (pyproject.toml) did not run successfully.\n",
      "  exit code: 1\n",
      "  \n",
      "  [48 lines of output]\n",
      "  C:\\Users\\17245\\AppData\\Local\\Temp\\pip-build-env-qvssr0_a\\overlay\\Lib\\site-packages\\setuptools\\dist.py:318: InformationOnly: Normalizing '0.8.1.rc2' to '0.8.1rc2'\n",
      "    self.metadata.version = self._normalize_version(self.metadata.version)\n",
      "  running bdist_wheel\n",
      "  running build\n",
      "  running build_py\n",
      "  creating build\n",
      "  creating build\\lib.win-amd64-cpython-311\n",
      "  creating build\\lib.win-amd64-cpython-311\\tokenizers\n",
      "  copying tokenizers\\__init__.py -> build\\lib.win-amd64-cpython-311\\tokenizers\n",
      "  creating build\\lib.win-amd64-cpython-311\\tokenizers\\models\n",
      "  copying tokenizers\\models\\__init__.py -> build\\lib.win-amd64-cpython-311\\tokenizers\\models\n",
      "  creating build\\lib.win-amd64-cpython-311\\tokenizers\\decoders\n",
      "  copying tokenizers\\decoders\\__init__.py -> build\\lib.win-amd64-cpython-311\\tokenizers\\decoders\n",
      "  creating build\\lib.win-amd64-cpython-311\\tokenizers\\normalizers\n",
      "  copying tokenizers\\normalizers\\__init__.py -> build\\lib.win-amd64-cpython-311\\tokenizers\\normalizers\n",
      "  creating build\\lib.win-amd64-cpython-311\\tokenizers\\pre_tokenizers\n",
      "  copying tokenizers\\pre_tokenizers\\__init__.py -> build\\lib.win-amd64-cpython-311\\tokenizers\\pre_tokenizers\n",
      "  creating build\\lib.win-amd64-cpython-311\\tokenizers\\processors\n",
      "  copying tokenizers\\processors\\__init__.py -> build\\lib.win-amd64-cpython-311\\tokenizers\\processors\n",
      "  creating build\\lib.win-amd64-cpython-311\\tokenizers\\trainers\n",
      "  copying tokenizers\\trainers\\__init__.py -> build\\lib.win-amd64-cpython-311\\tokenizers\\trainers\n",
      "  creating build\\lib.win-amd64-cpython-311\\tokenizers\\implementations\n",
      "  copying tokenizers\\implementations\\base_tokenizer.py -> build\\lib.win-amd64-cpython-311\\tokenizers\\implementations\n",
      "  copying tokenizers\\implementations\\bert_wordpiece.py -> build\\lib.win-amd64-cpython-311\\tokenizers\\implementations\n",
      "  copying tokenizers\\implementations\\byte_level_bpe.py -> build\\lib.win-amd64-cpython-311\\tokenizers\\implementations\n",
      "  copying tokenizers\\implementations\\char_level_bpe.py -> build\\lib.win-amd64-cpython-311\\tokenizers\\implementations\n",
      "  copying tokenizers\\implementations\\sentencepiece_bpe.py -> build\\lib.win-amd64-cpython-311\\tokenizers\\implementations\n",
      "  copying tokenizers\\implementations\\__init__.py -> build\\lib.win-amd64-cpython-311\\tokenizers\\implementations\n",
      "  copying tokenizers\\__init__.pyi -> build\\lib.win-amd64-cpython-311\\tokenizers\n",
      "  copying tokenizers\\models\\__init__.pyi -> build\\lib.win-amd64-cpython-311\\tokenizers\\models\n",
      "  copying tokenizers\\decoders\\__init__.pyi -> build\\lib.win-amd64-cpython-311\\tokenizers\\decoders\n",
      "  copying tokenizers\\normalizers\\__init__.pyi -> build\\lib.win-amd64-cpython-311\\tokenizers\\normalizers\n",
      "  copying tokenizers\\pre_tokenizers\\__init__.pyi -> build\\lib.win-amd64-cpython-311\\tokenizers\\pre_tokenizers\n",
      "  copying tokenizers\\processors\\__init__.pyi -> build\\lib.win-amd64-cpython-311\\tokenizers\\processors\n",
      "  copying tokenizers\\trainers\\__init__.pyi -> build\\lib.win-amd64-cpython-311\\tokenizers\\trainers\n",
      "  running build_ext\n",
      "  running build_rust\n",
      "  error: can't find Rust compiler\n",
      "  \n",
      "  If you are using an outdated pip version, it is possible a prebuilt wheel is available for this package but pip is not able to install from it. Installing from the wheel would avoid the need for a Rust compiler.\n",
      "  \n",
      "  To update pip, run:\n",
      "  \n",
      "      pip install --upgrade pip\n",
      "  \n",
      "  and then retry package installation.\n",
      "  \n",
      "  If you did intend to build this package from source, try installing a Rust compiler from your system package manager and ensure it is on the PATH during installation. Alternatively, rustup (available at https://rustup.rs) is the recommended way to download and update the Rust compiler toolchain.\n",
      "  [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "  ERROR: Failed building wheel for tokenizers\n",
      "ERROR: Could not build wheels for tokenizers, which is required to install pyproject.toml-based projects\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: jsonlines in c:\\users\\17245\\anaconda3\\lib\\site-packages (4.0.0)\n",
      "Requirement already satisfied: attrs>=19.2.0 in c:\\users\\17245\\anaconda3\\lib\\site-packages (from jsonlines) (23.1.0)\n",
      "Requirement already satisfied: shap in c:\\users\\17245\\anaconda3\\lib\\site-packages (0.45.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\17245\\anaconda3\\lib\\site-packages (from shap) (1.26.4)\n",
      "Requirement already satisfied: scipy in c:\\users\\17245\\anaconda3\\lib\\site-packages (from shap) (1.11.4)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\17245\\anaconda3\\lib\\site-packages (from shap) (1.2.2)\n",
      "Requirement already satisfied: pandas in c:\\users\\17245\\anaconda3\\lib\\site-packages (from shap) (2.1.4)\n",
      "Requirement already satisfied: tqdm>=4.27.0 in c:\\users\\17245\\anaconda3\\lib\\site-packages (from shap) (4.66.2)\n",
      "Requirement already satisfied: packaging>20.9 in c:\\users\\17245\\anaconda3\\lib\\site-packages (from shap) (23.1)\n",
      "Requirement already satisfied: slicer==0.0.7 in c:\\users\\17245\\anaconda3\\lib\\site-packages (from shap) (0.0.7)\n",
      "Requirement already satisfied: numba in c:\\users\\17245\\anaconda3\\lib\\site-packages (from shap) (0.59.0)\n",
      "Requirement already satisfied: cloudpickle in c:\\users\\17245\\anaconda3\\lib\\site-packages (from shap) (2.2.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\17245\\anaconda3\\lib\\site-packages (from tqdm>=4.27.0->shap) (0.4.6)\n",
      "Requirement already satisfied: llvmlite<0.43,>=0.42.0dev0 in c:\\users\\17245\\anaconda3\\lib\\site-packages (from numba->shap) (0.42.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\17245\\anaconda3\\lib\\site-packages (from pandas->shap) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\17245\\anaconda3\\lib\\site-packages (from pandas->shap) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\17245\\anaconda3\\lib\\site-packages (from pandas->shap) (2023.3)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\17245\\anaconda3\\lib\\site-packages (from scikit-learn->shap) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\17245\\anaconda3\\lib\\site-packages (from scikit-learn->shap) (2.2.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\17245\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->shap) (1.16.0)\n",
      "Requirement already satisfied: openai==1.12.0 in c:\\users\\17245\\anaconda3\\lib\\site-packages (1.12.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\17245\\anaconda3\\lib\\site-packages (from openai==1.12.0) (4.2.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\17245\\anaconda3\\lib\\site-packages (from openai==1.12.0) (1.8.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\17245\\anaconda3\\lib\\site-packages (from openai==1.12.0) (0.27.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\17245\\anaconda3\\lib\\site-packages (from openai==1.12.0) (2.7.0)\n",
      "Requirement already satisfied: sniffio in c:\\users\\17245\\anaconda3\\lib\\site-packages (from openai==1.12.0) (1.3.0)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\17245\\anaconda3\\lib\\site-packages (from openai==1.12.0) (4.66.2)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in c:\\users\\17245\\anaconda3\\lib\\site-packages (from openai==1.12.0) (4.9.0)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\17245\\anaconda3\\lib\\site-packages (from anyio<5,>=3.5.0->openai==1.12.0) (3.4)\n",
      "Requirement already satisfied: certifi in c:\\users\\17245\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->openai==1.12.0) (2024.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\17245\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->openai==1.12.0) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\17245\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai==1.12.0) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\17245\\anaconda3\\lib\\site-packages (from pydantic<3,>=1.9.0->openai==1.12.0) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.1 in c:\\users\\17245\\anaconda3\\lib\\site-packages (from pydantic<3,>=1.9.0->openai==1.12.0) (2.18.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\17245\\anaconda3\\lib\\site-packages (from tqdm>4->openai==1.12.0) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "!pip install convokit\n",
    "!pip install transformers[torch]\n",
    "!pip install accelerate\n",
    "# !pip install transformers_interpret\n",
    "!pip install git+https://github.com/allenai/longformer.git\n",
    "!pip install jsonlines\n",
    "!pip install shap\n",
    "!pip install openai==1.12.0     # Azure AI\n",
    "!pip install openai==0.28       # OPENAI API\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "JGFMti3WL90K"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import fetch_openml\n",
    "import time\n",
    "from sklearn import tree\n",
    "import pandas as pd\n",
    "import jsonlines\n",
    "from datetime import date\n",
    "import csv\n",
    "import openai\n",
    "openai.api_key = \"XXXXXXXXXXX\"\n",
    "\n",
    "import json\n",
    "import random\n",
    "import torch\n",
    "from torch.nn import L1Loss\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from scipy import stats\n",
    "\n",
    "import convokit\n",
    "import spacy\n",
    "from convokit import Corpus, Speaker, Utterance\n",
    "from convokit import download\n",
    "from convokit import TextParser\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vVpaL1ME3ACA"
   },
   "source": [
    "# 0. Load Data Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "79W5-E3HSwDP",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 0.1. OUM data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "def load_data_oum(label='after'):\n",
    "    final_convs = []\n",
    "    final_labels = []\n",
    "    wizards_data = []\n",
    "    moral_foundations = [\"care\", \"fairness\", \"liberty\", \"loyalty\", \"authority\", \"sanctity\", \"none\"]\n",
    "    input_files = {\"wizards\": \"wizards_dialogues.json\", \"final_argubot\": \"argubot_final_exp.json\",\n",
    "                   \"models_dialogues\": \"models_dialogues.json\"}\n",
    "    dials_with_scores = {\"wizards\": {}, \"final_argubot\": {}, \"models_dialogues\": {}}\n",
    "\n",
    "    for key in input_files:\n",
    "        input_file = input_files[key]\n",
    "        with open(input_file, \"r\", encoding=\"utf-8\") as f:\n",
    "            data = json.load(f)\n",
    "        for d in data:\n",
    "            is_wiki = False\n",
    "            for m in d[\"messages\"]:\n",
    "                if 'model' in m and (m['model'] == 'wikibot' or m['model'] == 'controlbot'):\n",
    "                    is_wiki = True\n",
    "                    break\n",
    "            if is_wiki:\n",
    "                continue\n",
    "            yes_no = 'none'\n",
    "            k = 'Did you vote for (Leave) or against (Remain) Brexit in the 2016 UK referendum?'\n",
    "            if k in d['participant_info']:\n",
    "                if d['participant_info'][k].lower() == 'against (remain)':\n",
    "                    yes_no = 'no'\n",
    "                elif d['participant_info'][k].lower() == 'for (leave)':\n",
    "                    yes_no = 'yes'\n",
    "                else:\n",
    "                    yes_no = 'none'\n",
    "\n",
    "            k = 'In the referendum on whether the UK should remain a member of the EU (BREXIT), how did you vote?'\n",
    "            if k in d['participant_info']:\n",
    "                if d['participant_info'][k].lower() == 'remain (against brexit)':\n",
    "                    yes_no = 'no'\n",
    "                elif d['participant_info'][k].lower() == 'leave (for brexit)':\n",
    "                    yes_no = 'yes'\n",
    "                else:\n",
    "                    yes_no = 'none'\n",
    "            k = 'Have you had at least one dose of an approved Covid-19 vaccine?'\n",
    "            if k in d['participant_info']:\n",
    "                if d['participant_info'][k].lower() == 'yes':\n",
    "                    yes_no = 'yes'\n",
    "                elif d['participant_info'][k].lower() == 'no':\n",
    "                    yes_no = 'no'\n",
    "            k = 'Are you a vegan?'\n",
    "            if k in d['participant_info']:\n",
    "                if d['participant_info'][k].lower() == 'yes':\n",
    "                    yes_no = 'yes'\n",
    "                elif d['participant_info'][k].lower() == 'no':\n",
    "                    yes_no = 'no'\n",
    "\n",
    "            if yes_no == 'none':\n",
    "                continue\n",
    "\n",
    "            if 'Questions' in d['participant_info']:\n",
    "                for q in d['participant_info']['Questions']:\n",
    "                    if \"final\" in input_file:\n",
    "                        if label == 'oum':\n",
    "                            continue\n",
    "                        if d['participant_info']['Questions'][q]['after'] == -1:\n",
    "                            continue\n",
    "                    elif d['participant_info']['Questions'][q]['before'] == -1 or d['participant_info']['Questions'][q]['after'] == -1:\n",
    "                        continue\n",
    "                    if 'good reasons' in q.lower():\n",
    "                        if d['topic'] != 'brexit' and 'not' in q.lower() and yes_no == 'no':\n",
    "                            continue\n",
    "                        if d['topic'] != 'brexit' and 'not' not in q.lower() and yes_no == 'yes':\n",
    "                            continue\n",
    "                        if 'leave' in q.lower() and yes_no == 'yes':\n",
    "                            continue\n",
    "                        if 'remain' in q.lower() and yes_no == 'no':\n",
    "                            continue\n",
    "                        if d[\"_id\"] not in dials_with_scores[key]:\n",
    "                            text = ''\n",
    "                            dials_with_scores[key][d[\"_id\"]] = {\"topic\": d[\"topic\"], \"dataset\": key}\n",
    "                            for message in d['messages']:\n",
    "                                if message['role'] == 'admin' or 'modified_argument' not in message:\n",
    "                                    continue\n",
    "\n",
    "                                text = text + '\\n\\n' + '<' + message['role'] + '>' + '\\n' + message['modified_argument']\n",
    "                            dials_with_scores[key][d[\"_id\"]]['text'] = text.strip()\n",
    "                            final_convs.append(text.strip())\n",
    "\n",
    "                    if 'good reasons' in q.lower():\n",
    "                        if False and label == 'oum':\n",
    "                            final_labels.append(float(d['participant_info']['Questions'][q]['after']) - float(d['participant_info']['Questions'][q]['before']))\n",
    "                        else:\n",
    "                            final_labels.append(float(d['participant_info']['Questions'][q]['after']))\n",
    "                        oum = d['participant_info']['Questions'][q]['after'] - d['participant_info']['Questions'][q]['before'] if \"final\" not in input_file else None\n",
    "                        dials_with_scores[key][d[\"_id\"]][\"good_reasons\"] = {\"oum\": oum, \"after\": d['participant_info']['Questions'][q]['after']}\n",
    "                        if 'before' in d['participant_info']['Questions'][q] and d['participant_info']['Questions'][q]['before'] != -1:\n",
    "                            dials_with_scores[key][d[\"_id\"]][\"good_reasons\"]['before'] = d['participant_info']['Questions'][q]['before']\n",
    "                        else:\n",
    "                            dials_with_scores[key][d[\"_id\"]][\"good_reasons\"]['before'] = None\n",
    "\n",
    "    assert len(final_convs) == len(final_labels)\n",
    "    return final_convs, final_labels\n",
    "\n",
    "def get_utterances(text):\n",
    "    # Splitting the input text into lines\n",
    "    lines = text.split('\\n')\n",
    "    # Variable to keep the cleaned lines\n",
    "    cleaned_lines = []\n",
    "    # Variable to keep track of whether the next line should be added\n",
    "    add_next_line = False\n",
    "    for line in lines:\n",
    "        # If the line is a participant tag, set the flag to add the next line\n",
    "        if line.strip() == '<participant>':\n",
    "            add_next_line = True\n",
    "        elif line.strip() in ['<woz>', '<chatbot>']:\n",
    "            add_next_line = True\n",
    "        elif add_next_line:\n",
    "            # If the flag is set, add this line to the cleaned list and reset the flag\n",
    "            cleaned_lines.append(line)\n",
    "            add_next_line = False\n",
    "    # Join the cleaned lines back into a single string\n",
    "    cleaned_text = '\\n'.join(cleaned_lines)\n",
    "    return cleaned_text\n",
    "\n",
    "### Bot/Woz's data\n",
    "conversations, labels = load_data_oum(label='after')\n",
    "utterances = [get_utterances(c) for c in conversations]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 0.2. Wikitac Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "def load_data_wikitac():\n",
    "    with open('../wikitactics.json') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    conversations = []\n",
    "    utterances_cleaned = []\n",
    "    labels = []\n",
    "    for dispute in data:\n",
    "        users = list()\n",
    "        conversation = ''\n",
    "        utt_cleaned = ''\n",
    "        for utterance in dispute['utterances']:\n",
    "            username = utterance['username']\n",
    "            text = utterance['text']\n",
    "            conversation += f\"<user_id={username}>\\n{text}\\n\\n\"\n",
    "            utt_cleaned += text + '\\n\\n'\n",
    "        conversations.append(conversation)\n",
    "        utterances_cleaned.append(utt_cleaned)\n",
    "        labels.append(dispute['escalation_label'])\n",
    "\n",
    "    return conversations, utterances_cleaned, labels\n",
    "\n",
    "conversations, utterances, labels = load_data_wikitac()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.3. AFD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_afd():\n",
    "    # Load the data from the JSON file\n",
    "    with open('../afd_1000_randomised_dialogues.json', 'r') as json_file:\n",
    "        data_dict = json.load(json_file)\n",
    "\n",
    "    # Extract the conversations, utterances, and labels from the data dictionary\n",
    "    conversations = data_dict['conversations']\n",
    "    utterances = data_dict['utterances']\n",
    "    labels = data_dict['labels']\n",
    "\n",
    "    return conversations, utterances, labels\n",
    "\n",
    "conversations, utterances, labels = load_data_afd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kCx3uy89CifY"
   },
   "source": [
    "# 2. Argument Quality Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YQBFyWltRKVK"
   },
   "source": [
    "## 2.1. Load **Conversation-level** Data for **Relation Annotation**.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sfCpXsaSRihS"
   },
   "source": [
    "### 2.1.1. Annotating the Argument Quality (AQ)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import time\n",
    "import os\n",
    "import openai\n",
    "import os\n",
    "import json\n",
    "\n",
    "def prompt_gpt4_errorlessly(prompt): \n",
    "    ok = False\n",
    "    while not ok:  # to avoid \"ServiceUnavailableError: The server is overloaded or not ready yet.\"\n",
    "        try:\n",
    "            response = openai.ChatCompletion.create(\n",
    "                        model=\"gpt-4-1106-preview\",\n",
    "                        messages=[\n",
    "                                  {\"role\": \"user\", \"content\": prompt}\n",
    "                                  ],\n",
    "                        max_tokens = 1000,\n",
    "                        temperature = 0\n",
    "                        )\n",
    "            ok = True\n",
    "\n",
    "        except Exception as ex:\n",
    "            print(\"error\", ex)\n",
    "            print(\"too much request, sleep for 5 seconds\")\n",
    "            time.sleep(5)\n",
    "\n",
    "    return response[\"choices\"][0][\"message\"][\"content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversations, utterances, labels = load_data_afd()\n",
    "\n",
    "human_args_quality_annotations = []\n",
    "\n",
    "for i, c in enumerate(conversations):\n",
    "    # prompt for OUM data\n",
    "    prompt = f\"\"\"{c}\\n\\n\n",
    "    The texts above show a dialogue on a controversial topic between an AI chatbot named 'woz' or 'bot' and a human participant. Both entities present arguments on the topic, possibly incorporating various rhetorical strategies, factual accuracy, relevance, coherence, among others. Now, please use chain-of-thought reasoning to evaluate the *average quality of arguments* (i.e., the discussion quality).\n",
    "    After the Chain-of-Thoughts reasoning step, you should assign an overall quality score to the entire discussion on a scale from 1 to 10, where 1 is of poor quality and 10 is of extremely good quality. Conclude your evaluation with the statement: 'Thus, the quality score of the discussion is: X', where X is the numeric score (real number) you've determined.\"\"\"\n",
    "\n",
    "    # prompt for Wikitac\n",
    "    prompt = f\"\"\"{c}\\n\\n\n",
    "    The texts above show a dialogue with respect to a potentially controversial edit between two or more individuals from Wikipedia Talk pages. All individuals present arguments on why they think the edit/s is or isn't reasonable, possibly incorporating various rhetorical strategies, factual accuracy, relevance, coherence, among others. Now, please use chain-of-thought reasoning to evaluate the *average quality of arguments* (i.e., the discussion quality).\n",
    "    After the Chain-of-Thoughts reasoning steps, you should assign an overall quality score to the entire discussion on a scale from 1 to 10, where 1 is of poor quality and 10 is of extremely good quality. Conclude your evaluation with the statement: 'Thus, the quality score of the discussion is: X', where X is the numeric score (real number) you've determined.\"\"\"\n",
    "\n",
    "    # prompt for AFD\n",
    "    prompt = f\"\"\"{c}\\n\\n\n",
    "    The texts above show a dialogue concerning a proposal for deleting a Wikipedia article, discussed between two or more individuals or users. All individuals present arguments on why they think the proposed deletion is or isn't reasonable, possibly incorporating various rhetorical strategies, factual accuracy, relevance, and coherence, among others. Please use chain-of-thought reasoning to evaluate the *average quality of arguments* (i.e., the discussion quality).\n",
    "    After the Chain-of-Thoughts reasoning step, you should assign an overall quality score to the entire discussion on a scale from 1 to 10, where 1 is of poor quality and 10 is of extremely good quality. Conclude your evaluation with the statement: 'Thus, the quality score of the discussion is: X', where X is the numeric score (real number) you've determined.\"\"\"\n",
    "\n",
    "    \n",
    "    ok = False\n",
    "    while not ok: \n",
    "        try:\n",
    "            response_text = prompt_gpt4_errorlessly(prompt)\n",
    "            ok = True\n",
    "\n",
    "        except Exception as ex:\n",
    "            print(\"error\", ex)\n",
    "            print(\"too much request, sleep for 5 seconds\")\n",
    "            time.sleep(5)\n",
    "\n",
    "    print('\\n\\n\\n', i)\n",
    "    print('\\n', response_text)\n",
    "    human_args_quality_annotations.append(response_text)\n",
    "\n",
    "import pandas as pd\n",
    "data = pd.DataFrame({'conversation': conversations, 'label': labels, 'human_AQ_annotation' : human_args_quality_annotations})\n",
    "# data.to_csv('542_oum_gpt4_AQ_1dim.csv', index=False)\n",
    "# data.to_csv('213_wikitac_gpt4_AQ_1dim.csv', index=False)\n",
    "data.to_csv('1000_afd_gpt4_AQ_1dim.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "79W5-E3HSwDP",
    "-imMDVSGSzJh",
    "5Zu0OwizGPxE",
    "hS_7KCSXGSmM",
    "rtiiPje_WTtA",
    "l1bKRhMZmsRG",
    "j-khhmrFmu8Q",
    "287x_FSmfNxE",
    "-j2B8RBkYVPC",
    "8anE2skqqQfU",
    "AsJI9_x8TOSL",
    "sfCpXsaSRihS",
    "kFqXeLf6Ak4S",
    "BxcXiIAE7XIS",
    "ZfoXdFse7ptF"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
