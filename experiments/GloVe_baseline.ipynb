{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6876c2b5-188f-4a43-b88f-e4358bb00587",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def load_glove_embeddings(glove_file_path):\n",
    "    embeddings_index = {}\n",
    "    with open(glove_file_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            values = line.split()\n",
    "            word = values[0]\n",
    "            try:\n",
    "                coefs = np.asarray(values[1:], dtype='float32')\n",
    "                embeddings_index[word] = coefs\n",
    "            except ValueError:\n",
    "                print(f\"Skipping line due to ValueError: {line[:50]}...\")\n",
    "    return embeddings_index\n",
    "\n",
    "# Example: Load 300-dimensional GloVe embeddings\n",
    "glove_file_path = './glove.42B.300d.txt'\n",
    "embeddings_index = load_glove_embeddings(glove_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d7b429f1-d5ce-43bd-bb74-c69d59ebbeb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Lexin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Lexin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Download NLTK stopwords and tokenizer\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Lowercase and remove non-alphanumeric characters\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'\\W+', ' ', text)\n",
    "    # Tokenize and remove stopwords\n",
    "    tokens = word_tokenize(text)\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "    return tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2156639c-65e2-4b80-8409-34bea0dfeed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_average_glove_embedding(tokens, embeddings_index, embedding_dim=50):\n",
    "    if not tokens:\n",
    "        return np.zeros(embedding_dim)\n",
    "    valid_embeddings = [embeddings_index[word] for word in tokens if word in embeddings_index]\n",
    "    if not valid_embeddings:\n",
    "        return np.zeros(embedding_dim)\n",
    "    avg_embedding = np.mean(valid_embeddings, axis=0)\n",
    "    return avg_embedding\n",
    "\n",
    "def compute_embeddings(conversations, embeddings_index, embedding_dim=50):\n",
    "    embeddings = []\n",
    "    for conversation in conversations:\n",
    "        tokens = preprocess_text(conversation)\n",
    "        avg_embedding = get_average_glove_embedding(tokens, embeddings_index, embedding_dim)\n",
    "        embeddings.append(avg_embedding)\n",
    "    return np.array(embeddings)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91f5c281-ffaa-4c76-9be6-3f699b6b73cf",
   "metadata": {},
   "source": [
    "# OUM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f90d3269-9292-4a0c-8652-030c52f37c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import json\n",
    "\n",
    "# Load the data\n",
    "def load_data_oum(label='after'):\n",
    "    final_convs = []\n",
    "    final_labels = []\n",
    "    final_experience_features = []\n",
    "    wizards_data = []\n",
    "    moral_foundations = [\"care\", \"fairness\", \"liberty\", \"loyalty\", \"authority\", \"sanctity\", \"none\"]\n",
    "    input_files = {\"wizards\": \"wizards_dialogues.json\", \"final_argubot\": \"argubot_final_exp.json\",\n",
    "                   \"models_dialogues\": \"models_dialogues.json\"}\n",
    "    dials_with_scores = {\"wizards\": {}, \"final_argubot\": {}, \"models_dialogues\": {}}\n",
    "\n",
    "\n",
    "    for key in input_files:\n",
    "        input_file = input_files[key]\n",
    "        with open(input_file, \"r\", encoding=\"utf-8\") as f:\n",
    "            data = json.load(f)\n",
    "        for d in data:\n",
    "            is_wiki = False\n",
    "            for m in d[\"messages\"]:\n",
    "                if 'model' in m and (m['model'] == 'wikibot' or m['model'] == 'controlbot'):\n",
    "                    is_wiki = True\n",
    "                    break\n",
    "            if is_wiki:\n",
    "                continue\n",
    "            yes_no = 'none'\n",
    "            k = 'Did you vote for (Leave) or against (Remain) Brexit in the 2016 UK referendum?'\n",
    "            if k in d['participant_info']:\n",
    "                if d['participant_info'][k].lower() == 'against (remain)':\n",
    "                    yes_no = 'no'\n",
    "                elif d['participant_info'][k].lower() == 'for (leave)':\n",
    "                    yes_no = 'yes'\n",
    "                else:\n",
    "                    yes_no = 'none'\n",
    "\n",
    "            k = 'In the referendum on whether the UK should remain a member of the EU (BREXIT), how did you vote?'\n",
    "            if k in d['participant_info']:\n",
    "                if d['participant_info'][k].lower() == 'remain (against brexit)':\n",
    "                    yes_no = 'no'\n",
    "                elif d['participant_info'][k].lower() == 'leave (for brexit)':\n",
    "                    yes_no = 'yes'\n",
    "                else:\n",
    "                    yes_no = 'none'\n",
    "            k = 'Have you had at least one dose of an approved Covid-19 vaccine?'\n",
    "            if k in d['participant_info']:\n",
    "                if d['participant_info'][k].lower() == 'yes':\n",
    "                    yes_no = 'yes'\n",
    "                elif d['participant_info'][k].lower() == 'no':\n",
    "                    yes_no = 'no'\n",
    "            k = 'Are you a vegan?'\n",
    "            if k in d['participant_info']:\n",
    "                if d['participant_info'][k].lower() == 'yes':\n",
    "                    yes_no = 'yes'\n",
    "                elif d['participant_info'][k].lower() == 'no':\n",
    "                    yes_no = 'no'\n",
    "\n",
    "            if yes_no == 'none':\n",
    "                continue\n",
    "\n",
    "            if 'Questions' in d['participant_info']:\n",
    "                for q in d['participant_info']['Questions']:\n",
    "                    if \"final\" in input_file:\n",
    "                        if label == 'oum':\n",
    "                            continue\n",
    "                        if d['participant_info']['Questions'][q]['after'] == -1:\n",
    "                            continue\n",
    "                    elif d['participant_info']['Questions'][q]['before'] == -1 or d['participant_info']['Questions'][q]['after'] == -1:\n",
    "                        continue\n",
    "                    if 'good reasons' in q.lower():\n",
    "                        if d['topic'] != 'brexit' and 'not' in q.lower() and yes_no == 'no':\n",
    "                            continue\n",
    "                        if d['topic'] != 'brexit' and 'not' not in q.lower() and yes_no == 'yes':\n",
    "                            continue\n",
    "                        if 'leave' in q.lower() and yes_no == 'yes':\n",
    "                            continue\n",
    "                        if 'remain' in q.lower() and yes_no == 'no':\n",
    "                            continue\n",
    "                        if d[\"_id\"] not in dials_with_scores[key]:\n",
    "                            text = ''\n",
    "                            dials_with_scores[key][d[\"_id\"]] = {\"topic\": d[\"topic\"], \"dataset\": key}\n",
    "                            for message in d['messages']:\n",
    "                                if message['role'] == 'admin' or 'modified_argument' not in message:\n",
    "                                    continue\n",
    "\n",
    "                                text = text + '\\n\\n' + '<' + message['role'] + '>' + '\\n' + message['modified_argument']\n",
    "                            dials_with_scores[key][d[\"_id\"]]['text'] = text.strip()\n",
    "                            final_convs.append(text.strip())\n",
    "\n",
    "                    if 'good reasons' in q.lower():\n",
    "                        if False and label == 'oum': \n",
    "                            final_labels.append(float(d['participant_info']['Questions'][q]['after']) - float(d['participant_info']['Questions'][q]['before']))\n",
    "                        else:\n",
    "                            final_labels.append(float(d['participant_info']['Questions'][q]['after']))\n",
    "                        oum = d['participant_info']['Questions'][q]['after'] - d['participant_info']['Questions'][q]['before'] if \"final\" not in input_file else None\n",
    "                        dials_with_scores[key][d[\"_id\"]][\"good_reasons\"] = {\"oum\": oum, \"after\": d['participant_info']['Questions'][q]['after']}\n",
    "                        if 'before' in d['participant_info']['Questions'][q] and d['participant_info']['Questions'][q]['before'] != -1:\n",
    "                            dials_with_scores[key][d[\"_id\"]][\"good_reasons\"]['before'] = d['participant_info']['Questions'][q]['before']\n",
    "                        else:\n",
    "                            dials_with_scores[key][d[\"_id\"]][\"good_reasons\"]['before'] = None\n",
    "\n",
    "                        engagement_features = list(d['participant_info']['Engagement'].values())\n",
    "                        chat_content_features = list(d['participant_info']['Chat_Content'].values())\n",
    "                        final_experience_features.append(engagement_features + chat_content_features)\n",
    "\n",
    "    assert len(final_convs) == len(final_labels)\n",
    "    return final_convs, final_labels #, final_experience_features\n",
    "conversations, labels = load_data_oum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a36fc44a-9bcd-4b0a-acee-c2c736552eb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error (MAE): 1.431(0.011)\n",
      "Spearman Correlation: 0.393(0.017)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold, cross_val_predict\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from scipy.stats import spearmanr\n",
    "import numpy as np\n",
    "\n",
    "# Compute embeddings\n",
    "X = compute_embeddings(conversations, embeddings_index, embedding_dim=300)\n",
    "y = np.array(labels)\n",
    "\n",
    "# Initialize Ridge Regression model\n",
    "ridge_reg = Ridge(alpha=1.0)\n",
    "\n",
    "mae_scores = []\n",
    "spearman_corr_scores = []\n",
    "\n",
    "for seed in [42, 123, 456]:\n",
    "    # Setup 7-fold cross-validation\n",
    "    kf = KFold(n_splits=7, shuffle=True, random_state=seed)\n",
    "    \n",
    "    # Perform cross-validation to get predictions\n",
    "    y_pred = cross_val_predict(ridge_reg, X, y, cv=kf)\n",
    "    \n",
    "    # Calculate Mean Absolute Error (MAE)\n",
    "    mae = mean_absolute_error(y, y_pred)\n",
    "    mae_scores.append(mae)\n",
    "    \n",
    "    # Calculate Spearman Correlation\n",
    "    spearman_corr, _ = spearmanr(y, y_pred)\n",
    "    spearman_corr_scores.append(spearman_corr)\n",
    "\n",
    "# Calculate mean and standard deviation\n",
    "mean_mae = np.mean(mae_scores)\n",
    "std_mae = np.std(mae_scores)\n",
    "\n",
    "mean_spearman_corr = np.mean(spearman_corr_scores)\n",
    "std_spearman_corr = np.std(spearman_corr_scores)\n",
    "\n",
    "# Print results in MEAN(SD) format\n",
    "print(f'Mean Absolute Error (MAE): {mean_mae:.3f}({std_mae:.3f})')\n",
    "print(f'Spearman Correlation: {mean_spearman_corr:.3f}({std_spearman_corr:.3f})')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ee8f08b-a92e-496a-a895-0046eaa5169e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Robustness analysis at topic-level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e965e93d-29bc-474b-909f-44c073d65fef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed= 42\n",
      "Overall Spearman correlation: 0.415\n",
      "Spearman correlation for topic 'covid': 0.109\n",
      "Spearman correlation for topic 'brexit': -0.032\n",
      "Spearman correlation for topic 'veganism': 0.152\n",
      "MAE for topic 'covid': 1.587\n",
      "MAE for topic 'brexit': 1.688\n",
      "MAE for topic 'veganism': 1.067\n",
      "seed= 123\n",
      "Overall Spearman correlation: 0.373\n",
      "Spearman correlation for topic 'covid': -0.012\n",
      "Spearman correlation for topic 'brexit': -0.065\n",
      "Spearman correlation for topic 'veganism': 0.075\n",
      "MAE for topic 'covid': 1.628\n",
      "MAE for topic 'brexit': 1.705\n",
      "MAE for topic 'veganism': 1.087\n",
      "seed= 456\n",
      "Overall Spearman correlation: 0.389\n",
      "Spearman correlation for topic 'covid': 0.033\n",
      "Spearman correlation for topic 'brexit': -0.010\n",
      "Spearman correlation for topic 'veganism': 0.094\n",
      "MAE for topic 'covid': 1.603\n",
      "MAE for topic 'brexit': 1.695\n",
      "MAE for topic 'veganism': 1.083\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def topic_categorisation(conv):\n",
    "    if 'vegan' in conv.lower():\n",
    "        return 'veganism'\n",
    "    elif 'covid' in conv.lower():\n",
    "        return 'covid'\n",
    "    elif 'brexit' in conv.lower():\n",
    "        return 'brexit'\n",
    "    else:\n",
    "        return 'other'\n",
    "\n",
    "\n",
    "# Compute embeddings\n",
    "X = compute_embeddings(conversations, embeddings_index, embedding_dim=300)\n",
    "y = np.array(labels)\n",
    "\n",
    "# Initialize Ridge Regression model\n",
    "ridge_reg = Ridge(alpha=1.0)\n",
    "\n",
    "for seed in [42, 123, 456]:\n",
    "    print('seed=', seed)\n",
    "    # Setup 7-fold cross-validation\n",
    "    kf = KFold(n_splits=7, shuffle=True, random_state=seed)\n",
    "    \n",
    "    # Perform cross-validation to get predictions\n",
    "    y_pred = cross_val_predict(ridge_reg, X, y, cv=kf)\n",
    "\n",
    "    df = pd.DataFrame({'Conversations': conversations, 'Labels': labels, 'Predictions': y_pred})\n",
    "    df['topic'] = df['Conversations'].map(topic_categorisation)\n",
    "    \n",
    "    # Calculate overall Spearman correlation\n",
    "    overall_corr, _ = spearmanr(df['Labels'], df['Predictions'])\n",
    "    print(f\"Overall Spearman correlation: {overall_corr:.3f}\")\n",
    "    \n",
    "    # Calculate Spearman correlation for each topic\n",
    "    topic_corrs = {}\n",
    "    topic_maes = {}\n",
    "    for topic in df['topic'].unique():\n",
    "        topic_df = df[df['topic'] == topic]\n",
    "        topic_corr, _ = spearmanr(topic_df['Labels'], topic_df['Predictions'])\n",
    "        topic_corrs[topic] = topic_corr\n",
    "        topic_maes[topic] = mean_absolute_error(topic_df['Labels'], topic_df['Predictions'])\n",
    "    \n",
    "    # Print Spearman correlation for each topic\n",
    "    for topic, corr in topic_corrs.items():\n",
    "        print(f\"Spearman correlation for topic '{topic}': {corr:.3f}\")\n",
    "    for topic, mae in topic_maes.items():\n",
    "        print(f\"MAE for topic '{topic}': {mae:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74c43cbb-d87f-46cb-955b-f58a9f127eef",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Wikitac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "22cad453-6c1c-479b-8349-f850b0dc0379",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "def load_data_wikitac():\n",
    "    with open('./wikitactics.json') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    conversations = []\n",
    "    utterances_cleaned = []\n",
    "    labels = []\n",
    "    # Extract conversations/disputes for ESCALATED disputes\n",
    "    for dispute in data:\n",
    "        users = list()\n",
    "        conversation = ''\n",
    "        utt_cleaned = ''\n",
    "        for utterance in dispute['utterances']:\n",
    "            username = utterance['username']\n",
    "            text = utterance['text']\n",
    "            conversation += f\"<user_id={username}>\\n{text}\\n\\n\"\n",
    "            utt_cleaned += text + '\\n\\n'\n",
    "        conversations.append(conversation)\n",
    "        utterances_cleaned.append(utt_cleaned)\n",
    "        labels.append(dispute['escalation_label'])\n",
    "\n",
    "    return conversations, utterances_cleaned, labels\n",
    "\n",
    "conversations, utterances, labels = load_data_wikitac()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "d6b669f2-8493-4101-adb2-2ddeb2340df4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Area Under ROC Curve (AUROC): 0.590(0.021)\n",
      "Area Under Precision-Recall Curve (AUPR): 0.573(0.021)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold, cross_val_predict\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "import numpy as np\n",
    "\n",
    "# Compute embeddings\n",
    "X = compute_embeddings(conversations, embeddings_index, embedding_dim=300)\n",
    "y = np.array(labels)\n",
    "\n",
    "# Initialize Logistic Regression model\n",
    "logistic_reg = LogisticRegression(max_iter=1000)\n",
    "\n",
    "auroc_scores = []\n",
    "aupr_scores = []\n",
    "\n",
    "for seed in [42, 123, 456]:\n",
    "    # Setup 7-fold cross-validation\n",
    "    kf = KFold(n_splits=7, shuffle=True, random_state=seed)\n",
    "    \n",
    "    # Perform cross-validation to get predictions\n",
    "    y_pred_proba = cross_val_predict(logistic_reg, X, y, cv=kf, method='predict_proba')[:, 1]\n",
    "    \n",
    "    # Calculate AUROC\n",
    "    auroc = roc_auc_score(y, y_pred_proba)\n",
    "    auroc_scores.append(auroc)\n",
    "    \n",
    "    # Calculate AUPR\n",
    "    aupr = average_precision_score(y, y_pred_proba)\n",
    "    aupr_scores.append(aupr)\n",
    "\n",
    "# Calculate mean and standard deviation\n",
    "mean_auroc = np.mean(auroc_scores)\n",
    "std_auroc = np.std(auroc_scores)\n",
    "\n",
    "mean_aupr = np.mean(aupr_scores)\n",
    "std_aupr = np.std(aupr_scores)\n",
    "\n",
    "# Print results in MEAN(SD) format\n",
    "print(f'Area Under ROC Curve (AUROC): {mean_auroc:.3f}({std_auroc:.3f})')\n",
    "print(f'Area Under Precision-Recall Curve (AUPR): {mean_aupr:.3f}({std_aupr:.3f})')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aaba637-d169-4ec2-ba51-2eb6c560c712",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# AFD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "fb6318f6-3ad1-4966-ad19-abe48ff218ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_afd():\n",
    "    # Load the data from the JSON file\n",
    "    with open('afd_1000_randomised_dialogues.json', 'r') as json_file:\n",
    "        data_dict = json.load(json_file)\n",
    "\n",
    "    # Extract the conversations, utterances, and labels from the data dictionary\n",
    "    conversations = data_dict['conversations']\n",
    "    utterances = data_dict['utterances']\n",
    "    labels = data_dict['labels']\n",
    "    labels = [1 if i == 0 else 0 for i in labels]\n",
    "    return conversations, utterances, labels\n",
    "\n",
    "conversations, utterances, labels = load_data_afd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "1c27eaf7-d459-46c2-b3d4-ef0cb4903ec3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Area Under ROC Curve (AUROC): 0.826(0.001)\n",
      "Area Under Precision-Recall Curve (AUPR): 0.565(0.003)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold, cross_val_predict\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "import numpy as np\n",
    "\n",
    "# Compute embeddings\n",
    "X = compute_embeddings(conversations, embeddings_index, embedding_dim=300)\n",
    "y = np.array(labels)\n",
    "\n",
    "# Initialize Logistic Regression model\n",
    "logistic_reg = LogisticRegression(max_iter=1000)\n",
    "\n",
    "auroc_scores = []\n",
    "aupr_scores = []\n",
    "\n",
    "for seed in [42, 123, 456]:\n",
    "    # Setup 7-fold cross-validation\n",
    "    kf = KFold(n_splits=7, shuffle=True, random_state=seed)\n",
    "    \n",
    "    # Perform cross-validation to get predictions\n",
    "    y_pred_proba = cross_val_predict(logistic_reg, X, y, cv=kf, method='predict_proba')[:, 1]\n",
    "    \n",
    "    # Calculate AUROC\n",
    "    auroc = roc_auc_score(y, y_pred_proba)\n",
    "    auroc_scores.append(auroc)\n",
    "    \n",
    "    # Calculate AUPR\n",
    "    aupr = average_precision_score(y, y_pred_proba)\n",
    "    aupr_scores.append(aupr)\n",
    "\n",
    "# Calculate mean and standard deviation\n",
    "mean_auroc = np.mean(auroc_scores)\n",
    "std_auroc = np.std(auroc_scores)\n",
    "\n",
    "mean_aupr = np.mean(aupr_scores)\n",
    "std_aupr = np.std(aupr_scores)\n",
    "\n",
    "# Print results in MEAN(SD) format\n",
    "print(f'Area Under ROC Curve (AUROC): {mean_auroc:.3f}({std_auroc:.3f})')\n",
    "print(f'Area Under Precision-Recall Curve (AUPR): {mean_aupr:.3f}({std_aupr:.3f})')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
